version: '3.8'

# Production override for docker-compose.yml
# Usage: docker-compose -f docker-compose.yml -f docker-compose.prod.yml up

services:
  # Production API with optimizations
  api:
    build:
      context: .
      dockerfile: cmd/api/Dockerfile
      target: production
    environment:
      - {{upper .ProjectName}}_APP_ENVIRONMENT=production
      - {{upper .ProjectName}}_LOGGER_LEVEL=info
      - {{upper .ProjectName}}_LOGGER_FORMAT=json
      - {{upper .ProjectName}}_SERVER_READ_TIMEOUT=30
      - {{upper .ProjectName}}_SERVER_WRITE_TIMEOUT=30
      - {{upper .ProjectName}}_SERVER_IDLE_TIMEOUT=120
    deploy:
      replicas: 3
      restart_policy:
        condition: on-failure
        delay: 10s
        max_attempts: 3
      resources:
        limits:
          cpus: '1.0'
          memory: 512M
        reservations:
          cpus: '0.5'
          memory: 256M
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # Production User Service
  user-service:
    build:
      context: .
      dockerfile: cmd/user-service/Dockerfile
      target: production
    environment:
      - {{upper .ProjectName}}_APP_ENVIRONMENT=production
      - {{upper .ProjectName}}_LOGGER_LEVEL=info
      - {{upper .ProjectName}}_LOGGER_FORMAT=json
      - {{upper .ProjectName}}_SERVER_READ_TIMEOUT=30
      - {{upper .ProjectName}}_SERVER_WRITE_TIMEOUT=30
      - {{upper .ProjectName}}_SERVER_IDLE_TIMEOUT=120
    deploy:
      replicas: 2
      restart_policy:
        condition: on-failure
        delay: 10s
        max_attempts: 3
      resources:
        limits:
          cpus: '0.5'
          memory: 256M
        reservations:
          cpus: '0.25'
          memory: 128M
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # Production Notification Service
  notification-service:
    build:
      context: .
      dockerfile: cmd/notification-service/Dockerfile
      target: production
    environment:
      - {{upper .ProjectName}}_APP_ENVIRONMENT=production
      - {{upper .ProjectName}}_LOGGER_LEVEL=info
      - {{upper .ProjectName}}_LOGGER_FORMAT=json
      - {{upper .ProjectName}}_SERVER_READ_TIMEOUT=30
      - {{upper .ProjectName}}_SERVER_WRITE_TIMEOUT=30
      - {{upper .ProjectName}}_SERVER_IDLE_TIMEOUT=120
    deploy:
      replicas: 2
      restart_policy:
        condition: on-failure
        delay: 10s
        max_attempts: 3
      resources:
        limits:
          cpus: '0.5'
          memory: 256M
        reservations:
          cpus: '0.25'
          memory: 128M
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # Production Worker
  worker:
    build:
      context: .
      dockerfile: cmd/worker/Dockerfile
      target: production
    environment:
      - {{upper .ProjectName}}_APP_ENVIRONMENT=production
      - {{upper .ProjectName}}_LOGGER_LEVEL=info
      - {{upper .ProjectName}}_LOGGER_FORMAT=json
      - {{upper .ProjectName}}_WORKER_COUNT=5
      - {{upper .ProjectName}}_WORKER_MAX_RETRIES=5
      - {{upper .ProjectName}}_WORKER_RETRY_DELAY=60
      - {{upper .ProjectName}}_WORKER_SHUTDOWN_GRACE=60
    deploy:
      replicas: 2
      restart_policy:
        condition: on-failure
        delay: 15s
        max_attempts: 3
      resources:
        limits:
          cpus: '1.0'
          memory: 512M
        reservations:
          cpus: '0.5'
          memory: 256M
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

{{- if eq .DatabaseType "postgres"}}
  # Production PostgreSQL with optimizations
  postgres:
    image: postgres:15-alpine
    environment:
      - POSTGRES_DB={{.ProjectName}}
      - POSTGRES_USER={{.ProjectName}}
      - POSTGRES_PASSWORD_FILE=/run/secrets/postgres_password
      - POSTGRES_INITDB_ARGS=--auth-host=scram-sha-256
      - POSTGRES_SHARED_PRELOAD_LIBRARIES=pg_stat_statements
    volumes:
      - postgres_prod_data:/var/lib/postgresql/data
      - ./configs/postgres/postgresql.conf:/etc/postgresql/postgresql.conf:ro
    command: ["postgres", "-c", "config_file=/etc/postgresql/postgresql.conf"]
    secrets:
      - postgres_password
    deploy:
      replicas: 1
      restart_policy:
        condition: on-failure
        delay: 10s
        max_attempts: 3
      resources:
        limits:
          cpus: '2.0'
          memory: 2G
        reservations:
          cpus: '1.0'
          memory: 1G
    logging:
      driver: "json-file"
      options:
        max-size: "50m"
        max-file: "5"

{{- else if eq .DatabaseType "mysql"}}
  # Production MySQL with optimizations
  mysql:
    image: mysql:8.0
    environment:
      - MYSQL_ROOT_PASSWORD_FILE=/run/secrets/mysql_root_password
      - MYSQL_DATABASE={{.ProjectName}}
      - MYSQL_USER={{.ProjectName}}
      - MYSQL_PASSWORD_FILE=/run/secrets/mysql_password
    volumes:
      - mysql_prod_data:/var/lib/mysql
      - ./configs/mysql/my.cnf:/etc/mysql/conf.d/custom.cnf:ro
    secrets:
      - mysql_root_password
      - mysql_password
    deploy:
      replicas: 1
      restart_policy:
        condition: on-failure
        delay: 10s
        max_attempts: 3
      resources:
        limits:
          cpus: '2.0'
          memory: 2G
        reservations:
          cpus: '1.0'
          memory: 1G
    logging:
      driver: "json-file"
      options:
        max-size: "50m"
        max-file: "5"

{{- else if eq .DatabaseType "mongodb"}}
  # Production MongoDB with optimizations
  mongodb:
    image: mongo:7.0
    environment:
      - MONGO_INITDB_ROOT_USERNAME={{.ProjectName}}
      - MONGO_INITDB_ROOT_PASSWORD_FILE=/run/secrets/mongodb_password
      - MONGO_INITDB_DATABASE={{.ProjectName}}
    volumes:
      - mongodb_prod_data:/data/db
      - ./configs/mongodb/mongod.conf:/etc/mongod.conf:ro
    command: ["mongod", "--config", "/etc/mongod.conf"]
    secrets:
      - mongodb_password
    deploy:
      replicas: 1
      restart_policy:
        condition: on-failure
        delay: 10s
        max_attempts: 3
      resources:
        limits:
          cpus: '2.0'
          memory: 2G
        reservations:
          cpus: '1.0'
          memory: 1G
    logging:
      driver: "json-file"
      options:
        max-size: "50m"
        max-file: "5"
{{- end}}

{{- if eq .MessageQueue "redis"}}
  # Production Redis with optimizations
  redis:
    image: redis:7-alpine
    volumes:
      - redis_prod_data:/data
      - ./configs/redis/redis.conf:/usr/local/etc/redis/redis.conf:ro
    command: ["redis-server", "/usr/local/etc/redis/redis.conf"]
    deploy:
      replicas: 1
      restart_policy:
        condition: on-failure
        delay: 10s
        max_attempts: 3
      resources:
        limits:
          cpus: '1.0'
          memory: 1G
        reservations:
          cpus: '0.5'
          memory: 512M
    logging:
      driver: "json-file"
      options:
        max-size: "20m"
        max-file: "3"

{{- else if eq .MessageQueue "nats"}}
  # Production NATS with optimizations
  nats:
    image: nats:2.10-alpine
    volumes:
      - ./configs/nats/nats.conf:/etc/nats/nats.conf:ro
    command: ["-c", "/etc/nats/nats.conf"]
    deploy:
      replicas: 1
      restart_policy:
        condition: on-failure
        delay: 10s
        max_attempts: 3
      resources:
        limits:
          cpus: '1.0'
          memory: 512M
        reservations:
          cpus: '0.5'
          memory: 256M
    logging:
      driver: "json-file"
      options:
        max-size: "20m"
        max-file: "3"

{{- else if eq .MessageQueue "rabbitmq"}}
  # Production RabbitMQ with optimizations
  rabbitmq:
    image: rabbitmq:3.12-management-alpine
    environment:
      - RABBITMQ_DEFAULT_USER={{.ProjectName}}
      - RABBITMQ_DEFAULT_PASS_FILE=/run/secrets/rabbitmq_password
    volumes:
      - rabbitmq_prod_data:/var/lib/rabbitmq
      - ./configs/rabbitmq/rabbitmq.conf:/etc/rabbitmq/rabbitmq.conf:ro
    secrets:
      - rabbitmq_password
    deploy:
      replicas: 1
      restart_policy:
        condition: on-failure
        delay: 10s
        max_attempts: 3
      resources:
        limits:
          cpus: '1.0'
          memory: 1G
        reservations:
          cpus: '0.5'
          memory: 512M
    logging:
      driver: "json-file"
      options:
        max-size: "20m"
        max-file: "3"

{{- else if eq .MessageQueue "kafka"}}
  # Production Kafka with optimizations
  kafka:
    image: confluentinc/cp-kafka:7.4.0
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:29092,PLAINTEXT_HOST://localhost:9092
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 3
      KAFKA_NUM_PARTITIONS: 3
      KAFKA_DEFAULT_REPLICATION_FACTOR: 3
      KAFKA_MIN_INSYNC_REPLICAS: 2
      KAFKA_LOG_RETENTION_HOURS: 168
      KAFKA_LOG_SEGMENT_BYTES: 1073741824
    volumes:
      - kafka_prod_data:/var/lib/kafka/data
    deploy:
      replicas: 3
      restart_policy:
        condition: on-failure
        delay: 15s
        max_attempts: 3
      resources:
        limits:
          cpus: '1.0'
          memory: 1G
        reservations:
          cpus: '0.5'
          memory: 512M
    logging:
      driver: "json-file"
      options:
        max-size: "20m"
        max-file: "3"
{{- end}}

  # Production Nginx with SSL
  nginx:
    image: nginx:alpine
    volumes:
      - ./configs/nginx/nginx.prod.conf:/etc/nginx/nginx.conf:ro
      - ./configs/nginx/conf.d:/etc/nginx/conf.d:ro
      - ./ssl:/etc/nginx/ssl:ro
      - ./logs/nginx:/var/log/nginx
    ports:
      - "80:80"
      - "443:443"
    deploy:
      replicas: 2
      restart_policy:
        condition: on-failure
        delay: 10s
        max_attempts: 3
      resources:
        limits:
          cpus: '0.5'
          memory: 256M
        reservations:
          cpus: '0.25'
          memory: 128M
    logging:
      driver: "json-file"
      options:
        max-size: "20m"
        max-file: "5"

  # Production Prometheus with data persistence
  prometheus:
    image: prom/prometheus:latest
    volumes:
      - ./configs/prometheus/prometheus.prod.yml:/etc/prometheus/prometheus.yml:ro
      - prometheus_prod_data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--storage.tsdb.retention.time=30d'
      - '--storage.tsdb.retention.size=10GB'
      - '--web.console.libraries=/etc/prometheus/console_libraries'
      - '--web.console.templates=/etc/prometheus/consoles'
      - '--web.enable-lifecycle'
      - '--web.enable-admin-api'
    deploy:
      replicas: 1
      restart_policy:
        condition: on-failure
        delay: 10s
        max_attempts: 3
      resources:
        limits:
          cpus: '1.0'
          memory: 2G
        reservations:
          cpus: '0.5'
          memory: 1G
    logging:
      driver: "json-file"
      options:
        max-size: "20m"
        max-file: "3"

  # Production Grafana with data persistence
  grafana:
    image: grafana/grafana:latest
    environment:
      - GF_SECURITY_ADMIN_PASSWORD_FILE=/run/secrets/grafana_admin_password
      - GF_USERS_ALLOW_SIGN_UP=false
      - GF_ANALYTICS_REPORTING_ENABLED=false
      - GF_ANALYTICS_CHECK_FOR_UPDATES=false
      - GF_SECURITY_COOKIE_SECURE=true
      - GF_SECURITY_COOKIE_SAMESITE=strict
    volumes:
      - grafana_prod_data:/var/lib/grafana
      - ./configs/grafana/dashboards:/etc/grafana/provisioning/dashboards:ro
      - ./configs/grafana/datasources:/etc/grafana/provisioning/datasources:ro
    secrets:
      - grafana_admin_password
    deploy:
      replicas: 1
      restart_policy:
        condition: on-failure
        delay: 10s
        max_attempts: 3
      resources:
        limits:
          cpus: '0.5'
          memory: 512M
        reservations:
          cpus: '0.25'
          memory: 256M
    logging:
      driver: "json-file"
      options:
        max-size: "20m"
        max-file: "3"

# Production secrets
secrets:
{{- if eq .DatabaseType "postgres"}}
  postgres_password:
    external: true
{{- else if eq .DatabaseType "mysql"}}
  mysql_root_password:
    external: true
  mysql_password:
    external: true
{{- else if eq .DatabaseType "mongodb"}}
  mongodb_password:
    external: true
{{- end}}
{{- if eq .MessageQueue "rabbitmq"}}
  rabbitmq_password:
    external: true
{{- end}}
  grafana_admin_password:
    external: true

volumes:
{{- if eq .DatabaseType "postgres"}}
  postgres_prod_data:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: /data/{{.ProjectName}}/postgres
{{- else if eq .DatabaseType "mysql"}}
  mysql_prod_data:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: /data/{{.ProjectName}}/mysql
{{- else if eq .DatabaseType "mongodb"}}
  mongodb_prod_data:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: /data/{{.ProjectName}}/mongodb
{{- end}}
{{- if eq .MessageQueue "redis"}}
  redis_prod_data:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: /data/{{.ProjectName}}/redis
{{- else if eq .MessageQueue "rabbitmq"}}
  rabbitmq_prod_data:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: /data/{{.ProjectName}}/rabbitmq
{{- else if eq .MessageQueue "kafka"}}
  kafka_prod_data:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: /data/{{.ProjectName}}/kafka
{{- end}}
  prometheus_prod_data:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: /data/{{.ProjectName}}/prometheus
  grafana_prod_data:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: /data/{{.ProjectName}}/grafana